{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ousr2a0qjto",
   "metadata": {},
   "source": [
    "# GTFS Bus Data Analysis\n",
    "\n",
    "This notebook analyzes NYC MTA bus GTFS data including:\n",
    "1. **GTFS Schedule Data** - Static transit schedule from `data/gtfs_b/`\n",
    "2. **GTFS Realtime Data** - Real-time vehicle positions from parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8y8ypf7o9",
   "metadata": {},
   "source": [
    "## Part 1: GTFS Schedule Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9kf1qx6pios",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GTFS Schedule Data...\n",
      "============================================================\n",
      "âœ“ Loaded all GTFS files successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load GTFS schedule files\n",
    "gtfs_path = 'data/gtfs_b/'\n",
    "\n",
    "print(\"Loading GTFS Schedule Data...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load key GTFS files\n",
    "calendar = pd.read_csv(gtfs_path + 'calendar.txt')\n",
    "calendar_dates = pd.read_csv(gtfs_path + 'calendar_dates.txt')\n",
    "routes = pd.read_csv(gtfs_path + 'routes.txt')\n",
    "trips = pd.read_csv(gtfs_path + 'trips.txt')\n",
    "stops = pd.read_csv(gtfs_path + 'stops.txt')\n",
    "agency = pd.read_csv(gtfs_path + 'agency.txt')\n",
    "\n",
    "print(\"âœ“ Loaded all GTFS files successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "z1cjbccgeq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“… SERVICE DATE COVERAGE\n",
      "============================================================\n",
      "\n",
      "Regular Service Patterns (calendar.txt):\n",
      "  Service start: 2025-01-29\n",
      "  Service end:   2025-06-28\n",
      "  Number of service patterns: 29\n",
      "\n",
      "  Service IDs by day of week:\n",
      "    EN_B5-Sunday: Sun\n",
      "    EN_B5-Weekday: Mon, Tue, Wed, Thu, Fri\n",
      "    EN_B5-Weekday-SDon: Mon, Tue, Wed, Thu, Fri\n",
      "    EN_B5-Saturday: Sat\n",
      "    FB_B5-Sunday: Sun\n",
      "    FB_B5-Weekday: Mon, Tue, Wed, Thu, Fri\n",
      "    FB_B5-Weekday-SDon: Mon, Tue, Wed, Thu, Fri\n",
      "    FB_B5-Saturday: Sat\n",
      "    FP_B5-Sunday: Sun\n",
      "    FP_B5-Weekday: Mon, Tue, Wed, Thu, Fri\n",
      "    FP_B5-Weekday-SDon: Mon, Tue, Wed, Thu, Fri\n",
      "    FP_B5-Saturday: Sat\n",
      "    GA_B5-Sunday: Sun\n",
      "    GA_B5-Weekday: Mon, Tue, Wed, Thu, Fri\n",
      "    GA_B5-Weekday-SDon: Mon, Tue, Wed, Thu, Fri\n",
      "    GA_B5-Saturday: Sat\n",
      "    GA_B5-Saturday-BM: Fri\n",
      "    JG_B5-Sunday: Sun\n",
      "    JG_B5-Sunday-BM: Sat\n",
      "    JG_B5-Weekday: Mon, Tue, Wed, Thu, Fri\n",
      "    JG_B5-Weekday-BM: Mon, Tue, Wed, Thu, Sun\n",
      "    JG_B5-Weekday-SDon: Mon, Tue, Wed, Thu, Fri\n",
      "    JG_B5-Weekday-SDon-BM: Mon, Tue, Wed, Thu, Sun\n",
      "    JG_B5-Saturday: Sat\n",
      "    JG_B5-Saturday-BM: Fri\n",
      "    UP_B5-Sunday: Sun\n",
      "    UP_B5-Weekday: Mon, Tue, Wed, Thu, Fri\n",
      "    UP_B5-Weekday-SDon: Mon, Tue, Wed, Thu, Fri\n",
      "    UP_B5-Saturday: Sat\n",
      "\n",
      "Service Exceptions (calendar_dates.txt):\n",
      "  Date range: 2025-03-31 to 2025-06-26\n",
      "  Total exception dates: 462\n",
      "  Added service (1): 7 dates\n",
      "  Removed service (2): 455 dates\n",
      "\n",
      "ðŸ“Š OVERALL DATE RANGE: 2025-01-29 to 2025-06-28\n"
     ]
    }
   ],
   "source": [
    "# Service Date Coverage\n",
    "print(\"\\nðŸ“… SERVICE DATE COVERAGE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert date columns to datetime\n",
    "calendar['start_date'] = pd.to_datetime(calendar['start_date'], format='%Y%m%d')\n",
    "calendar['end_date'] = pd.to_datetime(calendar['end_date'], format='%Y%m%d')\n",
    "calendar_dates['date'] = pd.to_datetime(calendar_dates['date'], format='%Y%m%d')\n",
    "\n",
    "# Calendar (regular service patterns)\n",
    "print(\"\\nRegular Service Patterns (calendar.txt):\")\n",
    "print(f\"  Service start: {calendar['start_date'].min().strftime('%Y-%m-%d')}\")\n",
    "print(f\"  Service end:   {calendar['end_date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"  Number of service patterns: {len(calendar)}\")\n",
    "print(f\"\\n  Service IDs by day of week:\")\n",
    "for idx, row in calendar.iterrows():\n",
    "    days = []\n",
    "    if row['monday'] == 1: days.append('Mon')\n",
    "    if row['tuesday'] == 1: days.append('Tue')\n",
    "    if row['wednesday'] == 1: days.append('Wed')\n",
    "    if row['thursday'] == 1: days.append('Thu')\n",
    "    if row['friday'] == 1: days.append('Fri')\n",
    "    if row['saturday'] == 1: days.append('Sat')\n",
    "    if row['sunday'] == 1: days.append('Sun')\n",
    "    print(f\"    {row['service_id']}: {', '.join(days)}\")\n",
    "\n",
    "# Calendar dates (exceptions)\n",
    "print(f\"\\nService Exceptions (calendar_dates.txt):\")\n",
    "print(f\"  Date range: {calendar_dates['date'].min().strftime('%Y-%m-%d')} to {calendar_dates['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"  Total exception dates: {len(calendar_dates)}\")\n",
    "print(f\"  Added service (1): {(calendar_dates['exception_type'] == 1).sum()} dates\")\n",
    "print(f\"  Removed service (2): {(calendar_dates['exception_type'] == 2).sum()} dates\")\n",
    "\n",
    "# Overall date coverage\n",
    "all_dates = pd.concat([\n",
    "    calendar[['start_date']].rename(columns={'start_date': 'date'}),\n",
    "    calendar[['end_date']].rename(columns={'end_date': 'date'}),\n",
    "    calendar_dates[['date']]\n",
    "])\n",
    "print(f\"\\nðŸ“Š OVERALL DATE RANGE: {all_dates['date'].min().strftime('%Y-%m-%d')} to {all_dates['date'].max().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2rseqkiupzg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸšŒ ROUTES SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total routes: 314\n",
      "Route types:\n",
      "  Bus: 274 routes\n",
      "  Type 711: 40 routes\n",
      "\n",
      "Sample routes:\n",
      "route_id route_short_name                  route_long_name  route_type\n",
      "      B1               B1      Bay Ridge - Manhattan Beach           3\n",
      "     B11              B11            Sunset Park - Midwood           3\n",
      "     B12              B12 Lefferts Gardens - East New York           3\n",
      "     B13              B13  Spring Creek - Wyckoff Hospital           3\n",
      "     B14              B14     Spring Creek - Crown Heights           3\n",
      "     B15              B15 Bedford Stuyvesant - JFK Airport           3\n",
      "     B16              B16     Bay Ridge - Lefferts Gardens           3\n",
      "     B17              B17         Canarsie - Crown Heights           3\n",
      "      B2               B2  Kings Hwy Station - Kings Plaza           3\n",
      "     B20              B20         Ridgewood - Spring Creek           3\n"
     ]
    }
   ],
   "source": [
    "# Routes Summary\n",
    "print(\"\\nðŸšŒ ROUTES SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTotal routes: {len(routes)}\")\n",
    "print(f\"Route types:\")\n",
    "route_types = routes['route_type'].value_counts()\n",
    "route_type_names = {3: 'Bus', 0: 'Light Rail', 1: 'Subway/Metro', 2: 'Rail'}\n",
    "for route_type, count in route_types.items():\n",
    "    type_name = route_type_names.get(route_type, f'Type {route_type}')\n",
    "    print(f\"  {type_name}: {count} routes\")\n",
    "\n",
    "print(f\"\\nSample routes:\")\n",
    "print(routes[['route_id', 'route_short_name', 'route_long_name', 'route_type']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0inmxe9b03u9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš TRIPS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total scheduled trips: 45,866\n",
      "Unique routes with trips: 65\n",
      "Unique service IDs: 29\n",
      "\n",
      "Top 10 routes by number of scheduled trips:\n",
      "  B6     (B6): 1,806 trips\n",
      "  B41    (B41): 1,737 trips\n",
      "  Q58    (Q58): 1,688 trips\n",
      "  B35    (B35): 1,450 trips\n",
      "  B38    (B38): 1,220 trips\n",
      "  B46    (B46): 1,188 trips\n",
      "  B15    (B15): 1,165 trips\n",
      "  B46-SBS (B46+): 1,117 trips\n",
      "  B17    (B17): 1,088 trips\n",
      "  B12    (B12): 1,042 trips\n",
      "\n",
      "Trips by direction:\n",
      "  Direction 0: 22,715\n",
      "  Direction 1: 23,151\n"
     ]
    }
   ],
   "source": [
    "# Trips Summary\n",
    "print(\"\\nðŸš TRIPS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTotal scheduled trips: {len(trips):,}\")\n",
    "print(f\"Unique routes with trips: {trips['route_id'].nunique()}\")\n",
    "print(f\"Unique service IDs: {trips['service_id'].nunique()}\")\n",
    "\n",
    "# Trips per route\n",
    "trips_per_route = trips.groupby('route_id').size().sort_values(ascending=False)\n",
    "print(f\"\\nTop 10 routes by number of scheduled trips:\")\n",
    "for route_id, count in trips_per_route.head(10).items():\n",
    "    route_name = routes[routes['route_id'] == route_id]['route_short_name'].values[0] if len(routes[routes['route_id'] == route_id]) > 0 else route_id\n",
    "    print(f\"  {route_name:6s} ({route_id}): {count:,} trips\")\n",
    "\n",
    "# Direction distribution\n",
    "if 'direction_id' in trips.columns:\n",
    "    print(f\"\\nTrips by direction:\")\n",
    "    print(f\"  Direction 0: {(trips['direction_id'] == 0).sum():,}\")\n",
    "    print(f\"  Direction 1: {(trips['direction_id'] == 1).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "swrfrexwe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ STOPS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total stops: 4,619\n",
      "\n",
      "Geographic coverage:\n",
      "  Latitude range:  40.572635 to 40.762524\n",
      "  Longitude range: -74.040876 to -73.789580\n",
      "\n",
      "Location types:\n",
      "  Stop/Platform: 4,619\n",
      "\n",
      "Sample stops:\n",
      " stop_id                  stop_name  stop_lat   stop_lon\n",
      "  300000 ORIENTAL BLVD/MACKENZIE ST 40.578350 -73.940029\n",
      "  300002   ORIENTAL BLVD/JAFFRAY ST 40.578066 -73.943029\n",
      "  300003  ORIENTAL BLVD/HASTINGS ST 40.577909 -73.944643\n",
      "  300004  ORIENTAL BLVD/FALMOUTH ST 40.577718 -73.946200\n",
      "  300006     ORIENTAL BLVD/DOVER ST 40.577353 -73.949552\n"
     ]
    }
   ],
   "source": [
    "# Stops Summary\n",
    "print(\"\\nðŸ“ STOPS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTotal stops: {len(stops):,}\")\n",
    "\n",
    "# Geographic bounds\n",
    "print(f\"\\nGeographic coverage:\")\n",
    "print(f\"  Latitude range:  {stops['stop_lat'].min():.6f} to {stops['stop_lat'].max():.6f}\")\n",
    "print(f\"  Longitude range: {stops['stop_lon'].min():.6f} to {stops['stop_lon'].max():.6f}\")\n",
    "\n",
    "# Location types if available\n",
    "if 'location_type' in stops.columns:\n",
    "    print(f\"\\nLocation types:\")\n",
    "    location_types = stops['location_type'].value_counts()\n",
    "    location_type_names = {0: 'Stop/Platform', 1: 'Station', 2: 'Entrance/Exit', 3: 'Generic Node', 4: 'Boarding Area'}\n",
    "    for loc_type, count in location_types.items():\n",
    "        type_name = location_type_names.get(loc_type, f'Type {loc_type}')\n",
    "        print(f\"  {type_name}: {count:,}\")\n",
    "\n",
    "print(f\"\\nSample stops:\")\n",
    "print(stops[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']].head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6sfsclesjxk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ“Š GTFS SCHEDULE SUMMARY\n",
      "============================================================\n",
      "\n",
      "Agency: MTA New York City Transit\n",
      "\n",
      "Service Period: 2025-01-29 to 2025-06-28\n",
      "Total Routes: 314\n",
      "Total Trips: 45,866\n",
      "Total Stops: 4,619\n",
      "Average Trips per Route: 146.1\n",
      "\n",
      "============================================================\n",
      "Ready to analyze realtime data!\n"
     ]
    }
   ],
   "source": [
    "# Overall GTFS Schedule Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š GTFS SCHEDULE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nAgency: {agency['agency_name'].values[0] if len(agency) > 0 else 'N/A'}\")\n",
    "print(f\"\\nService Period: {calendar['start_date'].min().strftime('%Y-%m-%d')} to {calendar['end_date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Total Routes: {len(routes):,}\")\n",
    "print(f\"Total Trips: {len(trips):,}\")\n",
    "print(f\"Total Stops: {len(stops):,}\")\n",
    "print(f\"Average Trips per Route: {len(trips) / len(routes):.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Ready to analyze realtime data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x02m9udaq4",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: GTFS Realtime Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xsl3cgsbkzr",
   "metadata": {},
   "outputs": [],
   "source": "# Load realtime vehicle position data\nprint(\"Loading Realtime Data...\")\nprint(\"=\"*60)\n\ndf = pd.read_parquet('data/COMPACTED_nyct_mta_bus_gtfsrt_2025-06-02.parquet')\n\nprint(f\"âœ“ Loaded {len(df):,} realtime vehicle position records\")\nprint(f\"  Date: June 2, 2025\")\nprint(f\"  Time range: {df['vehicle.timestamp'].min()} to {df['vehicle.timestamp'].max()}\")\nprint(f\"  Total routes: {df['vehicle.trip.route_id'].nunique()}\")\nprint(f\"  Total trips: {df['vehicle.trip.trip_id'].nunique()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nk7600ogowc",
   "metadata": {},
   "outputs": [],
   "source": "# Filter for B46 route\nprint(\"\\nðŸšŒ Filtering for B46 Route\")\nprint(\"=\"*60)\n\ndf_b46 = df[df['vehicle.trip.route_id'] == 'B46'].copy()\n\nprint(f\"\\nB46 Route Statistics:\")\nprint(f\"  Total records: {len(df_b46):,}\")\nprint(f\"  Unique trips: {df_b46['vehicle.trip.trip_id'].nunique()}\")\nprint(f\"  Unique vehicles: {df_b46['vehicle.vehicle.id'].nunique()}\")\nprint(f\"  Time range: {df_b46['vehicle.timestamp'].min()} to {df_b46['vehicle.timestamp'].max()}\")\n\n# Check for records without trip_id\nmissing_trip_id = df_b46['vehicle.trip.trip_id'].isna().sum()\nif missing_trip_id > 0:\n    print(f\"  âš ï¸  Records without trip_id: {missing_trip_id}\")\n    df_b46 = df_b46.dropna(subset=['vehicle.trip.trip_id'])\n    print(f\"  Continuing with {len(df_b46):,} records that have trip_ids\")\n\ndf_b46.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tni1i4ipgai",
   "metadata": {},
   "outputs": [],
   "source": "# Create trip-level summary with observation counts\nprint(\"\\nðŸ“Š B46 Trip-Level Summary\")\nprint(\"=\"*60)\n\n# Count observations per trip\nb46_trip_summary = df_b46.groupby('vehicle.trip.trip_id').agg({\n    'vehicle.trip.trip_id': 'count',\n    'vehicle.trip.direction_id': 'first',\n    'vehicle.timestamp': ['min', 'max']\n}).reset_index()\n\n# Flatten column names\nb46_trip_summary.columns = ['trip_id', 'num_observations', 'direction_id', 'first_timestamp', 'last_timestamp']\n\n# Calculate duration\nb46_trip_summary['duration_minutes'] = (\n    b46_trip_summary['last_timestamp'] - b46_trip_summary['first_timestamp']\n).dt.total_seconds() / 60\n\nprint(f\"\\nCreated summary for {len(b46_trip_summary)} unique B46 trips\")\nprint(f\"Observation count range: {b46_trip_summary['num_observations'].min()} to {b46_trip_summary['num_observations'].max()}\")\nprint(f\"\\nSample:\")\nb46_trip_summary.head(10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r6w2c3ueqge",
   "metadata": {},
   "outputs": [],
   "source": "# Check if trips exist in GTFS schedule\nprint(\"\\nðŸ” Checking Trips Against GTFS Schedule\")\nprint(\"=\"*60)\n\n# Filter GTFS trips for B46 route\ngtfs_b46_trips = trips[trips['route_id'] == 'B46'].copy()\n\nprint(f\"\\nGTFS Schedule for B46:\")\nprint(f\"  Scheduled trips in GTFS: {len(gtfs_b46_trips)}\")\nprint(f\"  Observed trips in realtime: {len(b46_trip_summary)}\")\n\n# Check which observed trips are in the schedule\nb46_trip_summary['in_schedule'] = b46_trip_summary['trip_id'].isin(gtfs_b46_trips['trip_id'])\n\nin_schedule_count = b46_trip_summary['in_schedule'].sum()\nnot_in_schedule_count = (~b46_trip_summary['in_schedule']).sum()\n\nprint(f\"\\nMatch Results:\")\nprint(f\"  âœ“ Trips found in schedule: {in_schedule_count}\")\nprint(f\"  âœ— Trips NOT in schedule: {not_in_schedule_count}\")\nprint(f\"  Match rate: {in_schedule_count / len(b46_trip_summary) * 100:.1f}%\")\n\n# Show some examples of trips not in schedule\nif not_in_schedule_count > 0:\n    print(f\"\\nSample trips NOT found in schedule:\")\n    print(b46_trip_summary[~b46_trip_summary['in_schedule']][['trip_id', 'num_observations', 'direction_id']].head())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r9fcgzl3yqg",
   "metadata": {},
   "outputs": [],
   "source": "# Get first stop information from schedule\nprint(\"\\nðŸš Getting First Stop Information from Schedule\")\nprint(\"=\"*60)\n\nprint(\"Loading stop_times.txt (this may take a moment)...\")\nstop_times = pd.read_csv(gtfs_path + 'stop_times.txt')\n\nprint(f\"âœ“ Loaded {len(stop_times):,} stop time records\")\n\n# Get first stop for each B46 trip (stop_sequence = 1 or minimum)\nb46_trip_ids = gtfs_b46_trips['trip_id'].tolist()\nstop_times_b46 = stop_times[stop_times['trip_id'].isin(b46_trip_ids)].copy()\n\nprint(f\"  Stop times for B46 trips: {len(stop_times_b46):,}\")\n\n# Get the first stop for each trip (lowest stop_sequence)\nfirst_stops = stop_times_b46.loc[stop_times_b46.groupby('trip_id')['stop_sequence'].idxmin()][\n    ['trip_id', 'arrival_time', 'stop_id', 'stop_sequence']\n].copy()\n\nprint(f\"  First stops identified: {len(first_stops)}\")\n\n# Join with stops to get stop names\nfirst_stops = first_stops.merge(\n    stops[['stop_id', 'stop_name']], \n    on='stop_id', \n    how='left'\n)\n\nprint(f\"\\nSample first stops:\")\nprint(first_stops.head())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vq8avyylv9e",
   "metadata": {},
   "outputs": [],
   "source": "# Create final trip analysis table\nprint(\"\\nðŸ“‹ Final B46 Trip Analysis Table\")\nprint(\"=\"*60)\n\n# Merge trip summary with first stop information\nb46_final = b46_trip_summary.merge(\n    first_stops[['trip_id', 'arrival_time', 'stop_name', 'stop_id']], \n    on='trip_id', \n    how='left'\n)\n\n# Rename columns for clarity\nb46_final = b46_final.rename(columns={\n    'arrival_time': 'scheduled_first_stop_time',\n    'stop_name': 'scheduled_first_stop_name',\n    'stop_id': 'scheduled_first_stop_id'\n})\n\n# Sort by in_schedule (True first) and then by num_observations (descending)\nb46_final = b46_final.sort_values(['in_schedule', 'num_observations'], ascending=[False, False])\n\nprint(f\"\\nFinal table created with {len(b46_final)} trips\")\nprint(f\"\\nColumns:\")\nfor col in b46_final.columns:\n    print(f\"  - {col}\")\n\nprint(f\"\\n{'='*60}\")\nprint(\"Summary Statistics:\")\nprint(f\"  Trips in schedule: {b46_final['in_schedule'].sum()}\")\nprint(f\"  Trips not in schedule: {(~b46_final['in_schedule']).sum()}\")\nprint(f\"  Average observations per trip: {b46_final['num_observations'].mean():.1f}\")\nprint(f\"  Median observations per trip: {b46_final['num_observations'].median():.1f}\")\n\n# Display the final table\nb46_final"
  },
  {
   "cell_type": "code",
   "id": "roegvvx6s1",
   "source": "# Additional insights and filtered views\nprint(\"\\nðŸ”Ž Additional Insights\")\nprint(\"=\"*60)\n\n# Show trips in schedule vs not\nprint(\"\\n1. TRIPS IN SCHEDULE:\")\nprint(\"-\" * 60)\nin_sched = b46_final[b46_final['in_schedule']].copy()\nprint(f\"   Count: {len(in_sched)}\")\nif len(in_sched) > 0:\n    print(f\"   Observations: {in_sched['num_observations'].sum():,} total\")\n    print(f\"   Average duration: {in_sched['duration_minutes'].mean():.1f} minutes\")\n    print(f\"\\n   Sample (top 10 by observations):\")\n    display(in_sched[['trip_id', 'num_observations', 'scheduled_first_stop_time', \n                       'scheduled_first_stop_name', 'duration_minutes']].head(10))\n\nprint(\"\\n2. TRIPS NOT IN SCHEDULE:\")\nprint(\"-\" * 60)\nnot_in_sched = b46_final[~b46_final['in_schedule']].copy()\nprint(f\"   Count: {len(not_in_sched)}\")\nif len(not_in_sched) > 0:\n    print(f\"   Observations: {not_in_sched['num_observations'].sum():,} total\")\n    print(f\"   Average duration: {not_in_sched['duration_minutes'].mean():.1f} minutes\")\n    print(f\"\\n   Sample (top 10 by observations):\")\n    display(not_in_sched[['trip_id', 'num_observations', 'direction_id', \n                           'first_timestamp', 'duration_minutes']].head(10))\n\n# Direction breakdown\nprint(\"\\n3. BREAKDOWN BY DIRECTION:\")\nprint(\"-\" * 60)\ndirection_stats = b46_final.groupby('direction_id').agg({\n    'trip_id': 'count',\n    'num_observations': 'sum',\n    'in_schedule': 'sum'\n}).rename(columns={'trip_id': 'trip_count', 'in_schedule': 'scheduled_trip_count'})\nprint(direction_stats)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "pq2nk6v9wfk",
   "source": "# Create a clean export version of the table\nprint(\"\\nðŸ’¾ Export-Ready Table\")\nprint(\"=\"*60)\n\n# Select and reorder columns for export\nexport_columns = [\n    'trip_id',\n    'num_observations', \n    'in_schedule',\n    'scheduled_first_stop_time',\n    'scheduled_first_stop_name',\n    'direction_id',\n    'first_timestamp',\n    'last_timestamp',\n    'duration_minutes'\n]\n\nb46_export = b46_final[export_columns].copy()\n\n# Format the table for better readability\nb46_export['in_schedule'] = b46_export['in_schedule'].map({True: 'Yes', False: 'No'})\nb46_export['duration_minutes'] = b46_export['duration_minutes'].round(1)\n\nprint(f\"\\nExport table ready with {len(b46_export)} rows and {len(b46_export.columns)} columns\")\nprint(f\"\\nYou can export this to CSV with:\")\nprint(\"  b46_export.to_csv('b46_trip_analysis.csv', index=False)\")\n\nprint(f\"\\nFull table preview (showing all {len(b46_export)} rows):\")\nb46_export",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenstreet-bus-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}